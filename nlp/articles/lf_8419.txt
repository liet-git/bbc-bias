 F-N-S-T-A-R-T. 8419 F-N-E-N-D.  D-A-T-E-S-T-A-R-T. 2023-12-20 D-A-T-E-E-N-D.  T-I-T-L-E-S-T-A-R-T. Meta's moderation of Israel-Gaza footage criticised. T-I-T-L-E-E-N-D.  T-E-X-T-S-T-A-R-T. Social media has an enormous role in shaping perceptions of this conflict, and two of the most popular and therefore influential platforms – Facebook and Instagram – are owned by one company, Meta. So the decisions it makes about what content people can and can’t see really matter. Today, Meta’s Oversight Board has ruled it got two of those decisions wrong. One related to an Instagram video which showed the deadly consequences of a strike on Al-Shifa Hospital in Gaza. The other concerned footage on Facebook of an Israeli woman being kidnapped. Both were initially taken down by Meta. The board has ruled they shouldn’t have been. It urges Meta to “respond more quickly to changing circumstances on the ground” and suggests the use of automated moderating tools (rather than a human moderator) increases the likelihood of “valuable” posts being wrongly suppressed. The board admits such decisions are “very difficult”, and acknowledges Meta’s responsibility not to incite hatred. But it says the firm also has to focus on freedom of expression for all sides. “These testimonies are important not just for the speakers, but for users around the world who are seeking timely and diverse information,” says Board co-chair Michael McConnell. T-E-X-T-E-N-D. 